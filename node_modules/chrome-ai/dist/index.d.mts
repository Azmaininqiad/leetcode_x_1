import { LanguageModelV1, LanguageModelV1CallOptions, LanguageModelV1FunctionToolCall, LanguageModelV1FinishReason, LanguageModelV1CallWarning, LanguageModelV1LogProbs, LanguageModelV1StreamPart, EmbeddingModelV1, EmbeddingModelV1Embedding } from '@ai-sdk/provider';
import { TextEmbedder } from '@mediapipe/tasks-text';

declare enum ChromeAICapabilityAvailability {
    /**
     * the device or browser does not support prompting a language model at all
     */
    NO = "no",
    /**
     * the device or browser supports prompting a language model, but it needs to be downloaded before it can be used
     */
    AFTER_DOWNLOAD = "after-download",
    /**
     * the device or browser supports prompting a language model and itâ€™s ready to be used without any downloading steps
     */
    READILY = "readily"
}

// https://github.com/explainers-by-googlers/prompt-api



interface ChromeAIAssistantCapabilities {
  available: ChromeAICapabilityAvailability;
  defaultTemperature: number;
  defaultTopK: number;
  maxTopK: number;
}

interface ChromeAIAssistantCreateOptions extends Record<string, any> {
  temperature?: number;
  topK?: number;
}

interface ChromeAIAssistant {
  destroy: () => Promise<void>;
  prompt: (prompt: string) => Promise<string>;
  promptStreaming: (prompt: string) => ReadableStream<string>;
}

interface ChromeAIAssistantFactory {
  capabilities: () => Promise<ChromeAIAssistantCapabilities>;
  create: (
    options?: ChromeAIAssistantCreateOptions
  ) => Promise<ChromeAIAssistant>;
}

interface ChromePromptAPI extends Record<string, any> {
  assistant: ChromeAIAssistantFactory;
}

interface PolyfillChromeAIOptions {
  modelAssetPath: string;
  wasmLoaderPath: string;
  wasmBinaryPath: string;
}

declare global {
  var ai: ChromePromptAPI;
  var model = ai;
  var __polyfill_ai_options__: Partial<PolyfillChromeAIOptions> | undefined;
}

type ChromeAIChatModelId = 'text';
interface ChromeAIChatSettings extends ChromeAIAssistantCreateOptions {
}
declare class ChromeAIChatLanguageModel implements LanguageModelV1 {
    readonly specificationVersion = "v1";
    readonly defaultObjectGenerationMode = "json";
    readonly modelId: ChromeAIChatModelId;
    readonly provider = "gemini-nano";
    readonly supportsImageUrls = false;
    readonly supportsStructuredOutputs = false;
    options: ChromeAIChatSettings;
    constructor(modelId: ChromeAIChatModelId, options?: ChromeAIChatSettings);
    private session;
    private getSession;
    private formatMessages;
    doGenerate: (options: LanguageModelV1CallOptions) => Promise<{
        text?: string;
        toolCalls?: LanguageModelV1FunctionToolCall[];
        finishReason: LanguageModelV1FinishReason;
        usage: {
            promptTokens: number;
            completionTokens: number;
        };
        rawCall: {
            rawPrompt: unknown;
            rawSettings: Record<string, unknown>;
        };
        rawResponse?: {
            headers?: Record<string, string>;
        };
        warnings?: LanguageModelV1CallWarning[];
        logprobs?: LanguageModelV1LogProbs;
    }>;
    doStream: (options: LanguageModelV1CallOptions) => Promise<{
        stream: ReadableStream<LanguageModelV1StreamPart>;
        rawCall: {
            rawPrompt: unknown;
            rawSettings: Record<string, unknown>;
        };
        rawResponse?: {
            headers?: Record<string, string>;
        };
        warnings?: LanguageModelV1CallWarning[];
    }>;
}

interface ChromeAIEmbeddingModelSettings {
    /**
     * An optional base path to specify the directory the Wasm files should be loaded from.
     * @default 'https://pub-ddcfe353995744e89b8002f16bf98575.r2.dev/text_wasm_internal.js'
     */
    wasmLoaderPath?: string;
    /**
     * It's about 6mb before gzip.
     * @default 'https://pub-ddcfe353995744e89b8002f16bf98575.r2.dev/text_wasm_internal.wasm'
     */
    wasmBinaryPath?: string;
    /**
     * The model path to the model asset file.
     * It's about 6.1mb before gzip.
     * @default 'https://pub-ddcfe353995744e89b8002f16bf98575.r2.dev/universal_sentence_encoder.tflite'
     */
    modelAssetPath?: string;
    /**
     * Whether to normalize the returned feature vector with L2 norm. Use this
     * option only if the model does not already contain a native L2_NORMALIZATION
     * TF Lite Op. In most cases, this is already the case and L2 norm is thus
     * achieved through TF Lite inference.
     * @default false
     */
    l2Normalize?: boolean;
    /**
     * Whether the returned embedding should be quantized to bytes via scalar
     * quantization. Embeddings are implicitly assumed to be unit-norm and
     * therefore any dimension is guaranteed to have a value in [-1.0, 1.0]. Use
     * the l2_normalize option if this is not the case.
     * @default false
     */
    quantize?: boolean;
    /**
     * Overrides the default backend to use for the provided model.
     */
    delegate?: 'CPU' | 'GPU';
}
declare class ChromeAIEmbeddingModel implements EmbeddingModelV1<string> {
    readonly specificationVersion = "v1";
    readonly provider = "google-mediapipe";
    readonly modelId: string;
    readonly supportsParallelCalls = true;
    readonly maxEmbeddingsPerCall: undefined;
    private settings;
    private modelAssetBuffer;
    private textEmbedder;
    constructor(settings?: ChromeAIEmbeddingModelSettings);
    protected getTextEmbedder: () => Promise<TextEmbedder>;
    doEmbed: (options: {
        values: string[];
        abortSignal?: AbortSignal;
    }) => Promise<{
        embeddings: Array<EmbeddingModelV1Embedding>;
        rawResponse?: Record<PropertyKey, any>;
    }>;
}

/**
 * Create a new ChromeAI model/embedding instance.
 * @param modelId 'text' | 'embedding'
 * @param settings Options for the model
 */
declare function chromeai(modelId?: ChromeAIChatModelId, settings?: ChromeAIChatSettings): ChromeAIChatLanguageModel;
declare function chromeai(modelId: 'embedding', settings?: ChromeAIEmbeddingModelSettings): ChromeAIEmbeddingModel;
declare namespace chromeai {
    var embedding: (settings?: ChromeAIEmbeddingModelSettings) => ChromeAIEmbeddingModel;
}

/**
 * Model: https://huggingface.co/oongaboongahacker/Gemini-Nano
 */
declare class PolyfillChromeAIAssistantFactory implements ChromeAIAssistantFactory {
    private aiOptions;
    constructor(aiOptions?: Partial<PolyfillChromeAIOptions>);
    private modelAssetBuffer;
    capabilities: () => Promise<ChromeAIAssistantCapabilities>;
    create: (options?: ChromeAIAssistantCreateOptions) => Promise<ChromeAIAssistant>;
}
declare const polyfillChromeAI: (options?: Partial<PolyfillChromeAIOptions>) => void;

export { ChromeAIChatLanguageModel, type ChromeAIChatModelId, type ChromeAIChatSettings, ChromeAIEmbeddingModel, type ChromeAIEmbeddingModelSettings, PolyfillChromeAIAssistantFactory, chromeai, polyfillChromeAI };
